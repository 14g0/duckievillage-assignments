{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81014140-e3d4-4297-9244-86a313e151b9",
   "metadata": {},
   "source": [
    "# MAC0318 Introdução à Programação de Robôs Móveis\n",
    "\n",
    "## Planejamento de rotas\n",
    "\n",
    "Nessa atividade, vamos usar técnicas de busca heurística em grafo para resolver o problema de encontra uma rota ótima. Um problema de planejamento é definido matematicamente por:\n",
    "- Um conjunto de estados $S$\n",
    "- Um estado inicial $s_0 \\in S$\n",
    "- Um estado meta $s_m \\in S$\n",
    "- Um conjunto de ações $A$\n",
    "- Uma função $A: S \\rightarrow 2^A$, que associa a cada estado um conjunto de ações aplicáveis $A(s)$ em um estado $s$\n",
    "- Uma função de transição $T: S \\times A \\rightarrow S$, que representa a transição de estado $T(s,a)$ causada por uma ação $a$ a partir de um estado $s$\n",
    "- Uma função de custo $C: S \\times A \\rightarrow \\mathbb{R}$, que associa um custo a uma transição.\n",
    "\n",
    "Note que o custo pode ser negativo, de fato representando uma recompensa. O objetivo do problema é encontrar uma sequência de ações aplicáveis $a_1, a_2, \\ldots, a_H$ tal que levem do estado inicial ao estado meta como mínimo custo. A sequência de ações produz uma trajetória\n",
    "$$\n",
    "  s_1 = T(s_0, a_1), \\, s_2 = T(s_1, a_2), \\, \\ldots, \\, s_H = T(s_{H-1}, a_H) ,\n",
    "$$\n",
    "para a qual $a_t \\in A(s_{t-1})$ para todo $t=1,\\ldots,H$. Por definição, uma solução para o problema requer que $H$ seja finito, que $s_H = s_m$ e que\n",
    "$$\n",
    "  C(s_0, a_1) + C(s_1, a_2) + \\dotsb + C(s_{H-1}, a_H)\n",
    "$$\n",
    "seja minímo sobre todas as sequências de ações aplicáveis que levem ao estado meta.\n",
    "\n",
    "Equivalentemente, o problema pode ser formulado como encontrar o caminho mais curto em um multigrafo $G$ com vértices $V$, arestas $A$ e pesos $C: A \\rightarrow \\mathbb{R}$ sobre as aretas. Note que em um multigrafo pode haver mais de uma aresta entre dois nós, portanto $A$ é um multiconjunto.\n",
    "\n",
    "## Grade de ocupação\n",
    "\n",
    "\n",
    "Vamos usar como domínio um mapa representado como **grade de ocupação**, isto é, uma matriz de 0s e 1s com 0 indicando uma célula ocupável (ou seja, que o agente pode ocupar) e 1 indicando uma célula ocupada (ou seja, que o agente _não_ pode ocupar). Vamos assumir uma 4-vizinhança: o agente pode se deslocar para a células ocupáveis acima, à direita, à esquerda e abaixo, como mostra a figura abaixo.\n",
    "\n",
    "<figure style=\"text-align: center\">\n",
    "    <img src=\"img/four-neighborhood.png\" width=\"300\">\n",
    "</figure>\n",
    "\n",
    "O ambiente será portanto representado como um grafo planar no qual os nós representam células e as aretas representam ações de locomoção. Vamos gerar um mundo aleatório assumindo que cada célula é ocupada independentemente com uma dada probabilidade. Vamos assumir que o agente inicia sempre na célula central em $(\\lfloor largura/2 \\rfloor, \\lfloor altura/2 \\rfloor)$, e que portanto é sempre desocupada. Os custos de todas as ações serão unitários.\n",
    "\n",
    "O problema de planejamento de rota nesse mundo é encontrar um caminho do nó incial a um nó meta desejado com o menor comprimento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "3c8ade45-31d9-4391-b8dd-5a1adcfbc517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importe as bibliotecas necessárias\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from collections import deque\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8d08ab45-14e5-4e22-956e-3cc1a070e0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos definir uma estrutura de dados para representar um estado (uma célula)\n",
    "@dataclass(frozen = True)\n",
    "class State:\n",
    "    x: int\n",
    "    y: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "7363fbf4-e080-4d3f-8951-c7f65cd0aef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A classe abaixo representa o problema de planejamento no mundo de grade de ocupação\n",
    "class World:\n",
    "    width: int\n",
    "    height: int\n",
    "    density: float\n",
    "    grid: np.ndarray\n",
    "    initial_state: State\n",
    "    \n",
    "    def __init__(self, width: int, height: int, density: float, message=True):\n",
    "        self.grid = np.random.rand(height, width) < density\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.initial_state = State(width//2, height//2)\n",
    "        self.grid[height//2,width//2] = False\n",
    "        if message:\n",
    "            print(\"World has\", self.grid.size-self.grid.sum(), \"occupable cells.\")\n",
    "        \n",
    "    def actions(self, state: State):\n",
    "        ''' Returns applicable actions at given `state`. '''\n",
    "        valid_actions = []\n",
    "        if state.x > 0 and not self.grid[state.y,state.x-1]:\n",
    "            valid_actions.append(\"left\")\n",
    "        if state.x < world.width - 1 and not self.grid[state.y,state.x+1]:\n",
    "            valid_actions.append(\"right\")\n",
    "        if state.y > 0 and not self.grid[state.y-1,state.x]:\n",
    "            valid_actions.append(\"up\")\n",
    "        if state.y < world.height - 1 and not self.grid[state.y+1,state.x]:\n",
    "            valid_actions.append(\"down\")\n",
    "        return valid_actions\n",
    "    \n",
    "    def next_state(self, state: State, action: str):\n",
    "        ''' Returns the successor state when applying the given `action` in given `state`. \n",
    "            Assumes `action` is applicable at `state`. '''\n",
    "        if action == \"left\":\n",
    "            return State(state.x-1, state.y)\n",
    "        elif action == \"right\":\n",
    "            return State(state.x+1, state.y)\n",
    "        elif action == \"up\":\n",
    "            return State(state.x, state.y-1)\n",
    "        elif action == \"down\":\n",
    "            return State(state.x, state.y+1)\n",
    "        \n",
    "    def cost(self, state: State, action: str):\n",
    "        ''' Returns cost of taking `action` in given `state`. '''\n",
    "        return 1.0\n",
    "        \n",
    "    def show(self, plan=None):\n",
    "        ''' Shows world and initial state. If plan is given, also displays trajectory. '''\n",
    "        M = 1-self.grid.astype(np.float32)\n",
    "        M[self.initial_state.y,self.initial_state.x] = 0.5\n",
    "        if plan is not None:\n",
    "            for state in plan:\n",
    "                M[state.y,state.x] = 0.5\n",
    "        plt.imshow(M, cmap='gray');        \n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "02c89b67-e286-4445-be13-cc54b563e614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World has 289 occupable cells.\n"
     ]
    }
   ],
   "source": [
    "# Criamos um mundo aleatório com as dimensões dadas (largura, altura, densidade de ocupação)\n",
    "world = World(40,10,0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "43672a6a-5859-40b8-b5d6-c3ef332d559f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizamos o mundo obtido -- células pretas são ocupadas, brancas são livres, cinza marca posição inicial\n",
    "world.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "25b29946-30dc-4ebf-8e98-c7c0f4116b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State(x=20, y=5)"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estado inicial\n",
    "world.initial_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "15f3cd79-b0a7-4afb-a5e3-9410494fd735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['right', 'up', 'down']"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ações aplicáveis no estado inicial\n",
    "world.actions(world.initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "38ca4fe9-2973-4794-b6d9-7f6b5f5376fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['down']"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ações aplicáveis no estado (x=0, y=0)\n",
    "world.actions(State(0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "f9b104ed-0170-4831-bb57-2231a644b25b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State(x=21, y=5)"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transição do estado inicial aplicando ação \"ir para a direita\"\n",
    "world.next_state(world.initial_state, \"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "3fe27fa6-a4cf-4dc9-80f1-59b4f9a8cf6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Custo da ação\n",
    "world.cost(world.initial_state, \"right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d78130-278e-4146-b9c8-7f57d5719b84",
   "metadata": {},
   "source": [
    "## Busca em profundidade\n",
    "\n",
    "A busca em profundidade consiste em explorar um caminho até que não haja mais ações aplicáveis, e então retornar ao estado anterior. Ela é implementada mantendo-se uma pilha de estados como fronteira e selectionando sempre um estado de maior altura na fronteira (distância do camimho do mais curto ao estado inicial). Memorizar os estados visitados torna a busca completa, evitando ciclos de visitas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "9d0856bf-7345-45c9-9608-fb98851c799f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Busca em profundidade com memória\n",
    "def depth_first_search(world: World, goal_state: State):\n",
    "    if goal_state.x >= world.width or goal_state.y >= world.height or goal_state.x < 0 or goal_state.y < 0:\n",
    "        print(\"Invalid goal state\", goal_state)\n",
    "        return None, np.Inf, 0\n",
    "    frontier = [world.initial_state]\n",
    "    path_cost = {world.initial_state: 0.0}\n",
    "    backtrack = {}\n",
    "    num_visited_states = 0\n",
    "    while frontier:\n",
    "        state = frontier.pop()\n",
    "        num_visited_states += 1\n",
    "        if state == goal_state:\n",
    "            # Found goal state, retrieve path\n",
    "            total_cost = path_cost[state]\n",
    "            plan = []\n",
    "            while state != world.initial_state:\n",
    "                plan.append(state)\n",
    "                state = backtrack[state]\n",
    "            plan.append(state)                \n",
    "            return plan, total_cost, num_visited_states\n",
    "        for action in world.actions(state):\n",
    "            next_state = world.next_state(state, action)\n",
    "            if next_state not in path_cost: # Avoids cycles\n",
    "                path_cost[next_state] = path_cost[state] + world.cost(state, action)\n",
    "                frontier.append(next_state)\n",
    "                backtrack[next_state] = state\n",
    "    return None, np.Inf, num_visited_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "63e6aff7-cb87-4d23-afdf-de752fa02736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found plan of cost 89.0 visiting 128 states.\n"
     ]
    }
   ],
   "source": [
    "# Goal state\n",
    "goal = State(0,0)\n",
    "\n",
    "# Find plan\n",
    "plan, cost, n_states = depth_first_search(world, goal)\n",
    "if plan is None:\n",
    "    print(\"Planning Failed! No possible plan exists.\")\n",
    "else:\n",
    "    print(\"Found plan of cost\", cost, \"visiting\", n_states, \"states.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "b595e0fb-bd58-452f-9ea3-8512bce75aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display world and plan trajectory (in gray)\n",
    "world.show(plan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb627ad-eb61-4fda-959b-fe106a72b836",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 💡Sua vez\n",
    "\n",
    "Antes de prosseguir, procure se familiarizar com o algoritmo da busca em profundidade. Rode o algoritmo com mundos diferentes, obtidos alterando a densidade de células ocupadas (use valores como 0.1 e 0.5). Use metas atingíveis e inatingíveis e veja os resultados, notando o número de estados visitados. Com o mundo fixo, procure encontrar o estao meta que leva ao pior caso para a busca em número de estados visitados.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482abf99-a3af-466d-8fc2-5be368024c55",
   "metadata": {},
   "source": [
    "## Busca em largura\n",
    "\n",
    "A busca em largura visita todos os nós a uma certa altura antes dos estados de altura estritamente maior. Ela é implementada mantendo-se uma fila de estados como fronteira e selecionando um nó de mínima altura na fronteira. A busca não requer memorização de estados para ser completa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "8884b5a6-7c60-48e0-a347-1f9e8e99fd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Busca em largura com memória\n",
    "def breadth_first_search(world: World, goal_state: State):\n",
    "    if goal_state.x >= world.width or goal_state.y >= world.height or goal_state.x < 0 or goal_state.y < 0:\n",
    "        print(\"Invalid goal state\", goal_state)\n",
    "        return None, np.Inf, 0\n",
    "    frontier = deque([world.initial_state])\n",
    "    path_cost = {world.initial_state: 0.0}\n",
    "    backtrack = {}\n",
    "    num_visited_states = 0\n",
    "    while frontier:\n",
    "        state = frontier.popleft()\n",
    "        num_visited_states += 1\n",
    "        if state == goal_state:\n",
    "            # Found goal state, retrieve path\n",
    "            total_cost = path_cost[state]\n",
    "            plan = []\n",
    "            while state != world.initial_state:\n",
    "                plan.append(state)\n",
    "                state = backtrack[state]\n",
    "            plan.append(state)                \n",
    "            return plan, total_cost, num_visited_states\n",
    "        for action in world.actions(state):\n",
    "            next_state = world.next_state(state, action)\n",
    "            if next_state not in path_cost: # Avoids cycles\n",
    "                path_cost[next_state] = path_cost[state] + world.cost(state, action)\n",
    "                frontier.append(next_state)\n",
    "                backtrack[next_state] = state\n",
    "    return None, np.Inf, num_visited_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "85dc0360-4976-4909-9d8f-cf0946fda90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found plan of cost 29.0 visiting 281 states.\n"
     ]
    }
   ],
   "source": [
    "# Goal state\n",
    "goal = State(0,0)\n",
    "\n",
    "# Find plan\n",
    "plan, cost, n_states = breadth_first_search(world, goal)\n",
    "if plan is None:\n",
    "    print(\"Planning Failed! No possible plan exists.\")\n",
    "else:\n",
    "    print(\"Found plan of cost\", cost, \"visiting\", n_states, \"states.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "c832c568-e95c-4e41-a2e0-179d0de2f614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display world and plan trajectory (in gray)\n",
    "world.show(plan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80322f6d-aef2-4bbc-b46c-240c8267c793",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 💡Sua vez\n",
    "\n",
    "Procure se familiarizar com o algoritmo da busca em largura. Rode o algoritmo com mundos diferentes, com metas atingíveis e inatingíveis e veja os resultados. Compare os custos e número de nós visitados entre as buscas em largura e em profundidade para um mesmo problema. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f21ab1-6c9b-44f9-b1f4-bfb25501991d",
   "metadata": {},
   "source": [
    "## Busca informanda\n",
    "\n",
    "A busca A* visita os nós seguindo uma função combinada entre o custo e uma heurística admissível, que subestima o custo restante de uma estado à meta. A busca não requer memorização de estados para ser completa ou ótima, mas a memorização aumenta a eficiência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "4c80841f-0f37-49c9-9819-4f54733c70fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos representar as transições na busca do caminho pela seguinte estrutura de dados\n",
    "@dataclass(order=True)\n",
    "class PrioritizedState:\n",
    "    priority: float\n",
    "    count: int # to break ties\n",
    "    state: State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "b1860e8f-cccc-474f-8900-d5d1de315394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PrioritizedState(priority=5, count=1, state=State(x=10, y=10))"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = [5,0,10]\n",
    "#heapq.heapify(L)\n",
    "L = []\n",
    "heapq.heappush(L, PrioritizedState(5, 1, State(10,10)))\n",
    "heapq.heappush(L, PrioritizedState(5, 2, State(1,10)))\n",
    "heapq.heappush(L, PrioritizedState(10, 0, State(10,10)))\n",
    "L\n",
    "\n",
    "heapq.heappop(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7e2daf-a218-4ca9-bb4f-5db457091e32",
   "metadata": {},
   "source": [
    "### Heurística\n",
    "\n",
    "Precisamos informar uma heurística $h(s)$ obedecendo as seguintes propriedades:\n",
    "- $h(s) \\geq 0$\n",
    "- $h(m) = 0$ para o estado meta $m$\n",
    "- $h(s) \\leq C(s,m)$, com $C(s,m)$ indicando o menor custo do caminho de $s$ a $m$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "b21df659-e50e-4a88-9f4e-549e568a2bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heuristic(state: State, goal_state: State):\n",
    "    ''' Computes Manhattan distance from state to goal_state). '''\n",
    "    return abs(state.x-goal_state.x) + abs(state.y-goal_state.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "3be6e2d2-3c5b-4198-b4af-f2342189e484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Qual a heurística para o estado inicial -- compare com solução ótima encontrada pela busca em largura (deve ser menor)\n",
    "heuristic(world.initial_state, goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "5dc0a483-6d97-40dd-b1dd-ae4397fbc2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Busca A* com memória\n",
    "def a_star_search(world: World, goal_state: State):\n",
    "    if goal_state.x >= world.width or goal_state.y >= world.height or goal_state.x < 0 or goal_state.y < 0:\n",
    "        print(\"Invalid goal state\", goal_state)\n",
    "        return None, np.Inf, 0\n",
    "    frontier = [PrioritizedState(heuristic(world.initial_state, goal_state), 0, world.initial_state)]\n",
    "    path_cost = {world.initial_state: 0.0}\n",
    "    backtrack = {}\n",
    "    num_visited_states = 0\n",
    "    counter = 0\n",
    "    while frontier:\n",
    "        pstate = heapq.heappop(frontier) # remove state with least priority f(n) = cost(n) + heuristic(n)\n",
    "        state = pstate.state\n",
    "        num_visited_states += 1\n",
    "        if state == goal_state:\n",
    "            # Found goal state, retrieve path\n",
    "            total_cost = path_cost[state]\n",
    "            plan = []\n",
    "            while state != world.initial_state:\n",
    "                plan.append(state)\n",
    "                state = backtrack[state]\n",
    "            plan.append(state)                \n",
    "            return plan, total_cost, num_visited_states\n",
    "        for action in world.actions(state):\n",
    "            next_state = world.next_state(state, action)\n",
    "            cost = path_cost[state] + world.cost(state, action)            \n",
    "            if (next_state not in path_cost) or (cost < path_cost[next_state]): # Avoids suboptimal paths\n",
    "                path_cost[next_state] = cost\n",
    "                f = cost + heuristic(next_state, goal_state)\n",
    "                counter += 1\n",
    "                heapq.heappush(frontier, PrioritizedState(f, counter, next_state) )\n",
    "                backtrack[next_state] = state\n",
    "    return None, np.Inf, num_visited_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "2b35725f-e58d-4ab9-9f3b-a28750cc2427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found plan of cost 29.0 visiting 91 states.\n"
     ]
    }
   ],
   "source": [
    "# Goal state\n",
    "goal = State(0,0)\n",
    "\n",
    "# Find plan\n",
    "plan, cost, n_states = a_star_search(world, goal)\n",
    "if plan is None:\n",
    "    print(\"Planning Failed! No possible plan exists.\")\n",
    "else:\n",
    "    print(\"Found plan of cost\", cost, \"visiting\", n_states, \"states.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "5a6b92ab-2249-43e9-bb33-44b8eec4bd1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display world and plan trajectory (in gray)\n",
    "world.show(plan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26010023-d8ff-4f21-9406-722d62e35224",
   "metadata": {},
   "source": [
    "## Comparação\n",
    "\n",
    "Vamos comparar as buscas com relação à qualidade da solução encontrada (custo) e a eficiência (número de estados visitados)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "df566f4b-352f-4c7f-82c9-06c6ce489d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A-star\n",
      "  - Average Cost: 30.08 \n",
      "  - Average Num. Iterations: 110.07\n",
      "BFS\n",
      "  - Average Cost: 30.08 \n",
      "  - Average Num. Iterations: 358.12\n",
      "DFS\n",
      "  - Average Cost: 118.55 \n",
      "  - Average Num. Iterations: 235.23\n"
     ]
    }
   ],
   "source": [
    "avg_cost_A = 0.0\n",
    "avg_cost_D = 0.0\n",
    "avg_it_A = 0\n",
    "avg_it_B = 0\n",
    "avg_it_D = 0\n",
    "\n",
    "N = 0\n",
    "for i in range(100):\n",
    "    myworld = World(50,10,0.1,False);\n",
    "    mygoal = None\n",
    "    for x in range(50):\n",
    "        for y in range(10):\n",
    "            if not myworld.grid[y,x]:\n",
    "                mygoal = State(x,y)\n",
    "                break\n",
    "        if mygoal is not None:\n",
    "            break\n",
    "    plan_A, cost_A, n_states_A = a_star_search(myworld, mygoal)\n",
    "    plan_B, cost_B, n_states_B = breadth_first_search(myworld, mygoal)\n",
    "    plan_D, cost_D, n_states_D = depth_first_search(myworld, mygoal)\n",
    "    \n",
    "    if cost_A != cost_B: # This should never be true!\n",
    "        print(\"Oh, Oh! Something went wrong...\")\n",
    "        print(f\"A-star: {cost_A}  {n_states_A}\")\n",
    "        print(f\"BFS: {cost_B}  {n_states_B}\")    \n",
    "        break\n",
    "        \n",
    "    if cost_A < np.inf: # Discard unsolvable problems\n",
    "        N += 1\n",
    "        avg_cost_A += cost_A\n",
    "        avg_cost_D += cost_D\n",
    "        avg_it_A += n_states_A\n",
    "        avg_it_B += n_states_B\n",
    "        avg_it_D += n_states_D\n",
    "\n",
    "print(\"A-star\\n  - Average Cost:\", f\"{avg_cost_A/N:.2f}\", \"\\n  - Average Num. Iterations:\", f\"{avg_it_A/N:.2f}\")\n",
    "print(\"BFS\\n  - Average Cost:\", f\"{avg_cost_A/N:.2f}\", \"\\n  - Average Num. Iterations:\", f\"{avg_it_B/N:.2f}\")\n",
    "print(\"DFS\\n  - Average Cost:\", f\"{avg_cost_D/N:.2f}\", \"\\n  - Average Num. Iterations:\", f\"{avg_it_D/N:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f9342c-dfb9-4bd7-a3cf-09610fc3f7d6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 💡Sua vez\n",
    "\n",
    "Desenha um mundo (a matriz da grade de ocupação) que maximize o desempenho da busca A* em comparação com as outras buscas. Reflita sobre as razões das ineficiências da busca não informada para pensar em uma grade de ocupação favorável para o A*. Depois, inverta o pensamento e desenhe uma matriz na qual A* desempenha de maneira similar à busca em largura e potencialmente pior que a busca em profundidade. Você espera encontrar situações assim em problemas de planejamento de rotas?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c762427-4b1a-441d-b3af-d78d19a65082",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
